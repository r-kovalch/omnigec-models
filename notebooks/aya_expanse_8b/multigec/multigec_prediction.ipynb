{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Reennon/multigec-models/blob/main/notebooks/aya_expanse_8b/multigec/multigec_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UsXRO225aQG5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"GIT_TOKEN\"] = userdata.get('git_token')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "aduMiBeD946F",
        "outputId": "0304fecc-d57b-44c6-85c3-2ac827beb0dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_IRXNxZaF4Y",
        "outputId": "b03f5e3b-dc87-47d5-aefe-9f173cea87dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'multigec-models'...\n",
            "remote: Enumerating objects: 109, done.\u001b[K\n",
            "remote: Counting objects: 100% (109/109), done.\u001b[K\n",
            "remote: Compressing objects: 100% (59/59), done.\u001b[K\n",
            "remote: Total 109 (delta 32), reused 68 (delta 19), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (109/109), 125.11 KiB | 6.25 MiB/s, done.\n",
            "Resolving deltas: 100% (32/32), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://$GIT_TOKEN@github.com/Reennon/multigec-models.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7b_-L4YdQdS",
        "outputId": "a4933e84-6dc1-4e49-b8bf-d8d5622225fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/multigec-models\n"
          ]
        }
      ],
      "source": [
        "%cd multigec-models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ak_WBUcgdWYE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ad50ec2-6f5c-49ae-b741-8e4a4adc5404"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ],
      "source": [
        "!git pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0zzclvTdlkE",
        "outputId": "8dc0fac3-83a9-4083-d9d2-2a25db3bf0b2",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.0/411.0 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.3/124.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.4/293.4 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m103.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m101.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m89.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m94.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m125.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.0/147.0 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for mosestokenizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for toolwrapper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for uctools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m109.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.4/123.4 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.6/436.6 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m119.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m335.7/335.7 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "adapters 1.1.0 requires transformers~=4.47.1, but you have transformers 4.50.3 which is incompatible.\n",
            "wtpsplit 2.1.1 requires huggingface-hub==0.25.2, but you have huggingface-hub 0.29.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -U bitsandbytes peft accelerate datasets sentencepiece wandb python-dotenv wtpsplit -q\n",
        "!pip install flash-attn --no-build-isolation -q\n",
        "!pip install wtpsplit==2.1.1 -q\n",
        "!pip install syntok==1.4.4 -q\n",
        "!pip install omegaconf -q\n",
        "!pip install wandb -q\n",
        "!pip install --upgrade transformers trl -q\n",
        "!pip install pandas numpy -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBGK2EtZO6tR",
        "outputId": "6ec41d24-5f1b-4b70-d0c1-5fb459e5c427"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "xLa_z_uleW1O"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from omegaconf import OmegaConf\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoConfig\n",
        "from huggingface_hub import login\n",
        "from src.utils.multigec import sentences, LANG_TO_CODE, LANG_CODE_TO_TOKEN\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "from src.instruction_templates import multigec_prompts\n",
        "\n",
        "import torch\n",
        "import wandb\n",
        "\n",
        "from transformers import BitsAndBytesConfig\n",
        "from tqdm import tqdm\n",
        "from trl.trainer import ConstantLengthDataset\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from transformers.trainer_callback import EarlyStoppingCallback\n",
        "\n",
        "from transformers import TrainingArguments\n",
        "from trl import SFTConfig, SFTTrainer\n",
        "from peft import LoraConfig\n",
        "\n",
        "from peft import PeftModel, PeftModelForCausalLM\n",
        "\n",
        "tqdm.pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ZrXeF2PMTA9C"
      },
      "outputs": [],
      "source": [
        "parameters = OmegaConf.load(\"./params/aya_expanse_8b.yaml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "2orS0nY-j3QY"
      },
      "outputs": [],
      "source": [
        "track     = \"minimal\"\n",
        "fine_tuned_model_name = f\"aya-expanse-8b-multigec\"\n",
        "\n",
        "hf_key   = userdata.get(\"hf_key\")\n",
        "secret_wandb = userdata.get(\"wandb_key\")\n",
        "\n",
        "in_path  = f\"/content/drive/MyDrive/multigec/datasets/multigec_{track}.csv\"\n",
        "out_path = f\"/content/drive/MyDrive/multigec/preds/multigec_test_{track}.csv\"\n",
        "\n",
        "out_model_dir = f\"/content/drive/MyDrive/multigec/models/{fine_tuned_model_name}\"\n",
        "QUANTIZE_4BIT = True\n",
        "device   = \"cuda:0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "5ATeEv_etKR1"
      },
      "outputs": [],
      "source": [
        "login(hf_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "oB4Vv3zFyHLd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cbe8184-c7cd-44e3-bb81-f71b6368a1d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: ‘-q’: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!env TORCH_USE_CUDA_DSA=1 -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls /content/drive/MyDrive/multigec/models"
      ],
      "metadata": {
        "id": "gp_eu-gkAWqS",
        "outputId": "1ce615a8-b636-45c6-dd32-bd25729110f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34maya-expanse-8b-multigec\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125,
          "referenced_widgets": [
            "2eee8ca85121462082e88ce307aee5ad",
            "9c999855ca7d4fd98b6f16128cf10df4",
            "f931f4e24a4b48ef9f7e1d9606518331",
            "c203414ceaf842ebbb46a9764d11c78c",
            "67c6b481780d4561b924d43d9be0e85a",
            "8c5d9bc68b2b4ee0992f60e66e4c777a",
            "f2abe29a43934883ba27e1f2a3db3b87",
            "375fec489ffa442098cc2c851e9d8d36",
            "c8956e6046a64df6ac3024b659883aef",
            "84c06e67211e4ecbb2628e19500524ab",
            "063563ce187b4d92b16e5d614e5ffd72"
          ]
        },
        "id": "npCYpk8StL1L",
        "outputId": "1901fa85-f2d9-48a5-dae7-34cdd8632e8f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2eee8ca85121462082e88ce307aee5ad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:470: UserWarning: Some weights of PeftModelForCausalLM were not initialized from the model checkpoint and are being ignored because you passed `ignore_mismatched_sizes=True`: - base_model.model.lm_head.weight: found shape torch.Size([255040, 4096]) in the checkpoint and torch.Size([255029, 4096]) in the model instantiated\n",
            "- base_model.model.model.embed_tokens.weight: found shape torch.Size([255040, 4096]) in the checkpoint and torch.Size([255029, 4096]) in the model instantiated.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "base_model = \"CohereForAI/aya-expanse-8b\"\n",
        "saved_checkpoint = out_model_dir + \"/checkpoint-700\"\n",
        "\n",
        "quantization_config = None\n",
        "if QUANTIZE_4BIT:\n",
        "  quantization_config = BitsAndBytesConfig(\n",
        "      load_in_4bit=True,\n",
        "      bnb_4bit_quant_type=\"nf4\",\n",
        "      bnb_4bit_use_double_quant=True,\n",
        "      bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "  )\n",
        "tokenizer = AutoTokenizer.from_pretrained(saved_checkpoint)\n",
        "config = AutoConfig.from_pretrained(base_model)\n",
        "base_model_instance = AutoModelForCausalLM.from_pretrained(\n",
        "    base_model,\n",
        "    config=config,\n",
        "    quantization_config=quantization_config,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=device,\n",
        "    attn_implementation=\"flash_attention_2\",\n",
        ")\n",
        "base_model_instance.resize_token_embeddings(len(tokenizer))\n",
        "model = PeftModelForCausalLM.from_pretrained(\n",
        "    base_model_instance,\n",
        "    saved_checkpoint,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=device,\n",
        "    ignore_mismatched_sizes=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "tc_-2FtptNPf"
      },
      "outputs": [],
      "source": [
        "multigec_df = pd.read_csv(in_path)\n",
        "train_df = multigec_df.loc[multigec_df.loc[:, \"split\"] == \"train\"]\n",
        "val_df = multigec_df.loc[multigec_df.loc[:, \"split\"] == \"val\"]\n",
        "test_df = multigec_df.loc[multigec_df.loc[:, \"split\"] == \"test\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def formatting_prompts_func(example):\n",
        "    language_code = LANG_TO_CODE[example[\"language\"]]\n",
        "    language_token = LANG_CODE_TO_TOKEN[language_code]\n",
        "\n",
        "    user_input = example['feature']\n",
        "    prompt_template = multigec_prompts[example[\"language\"]].prompt_template\n",
        "    instruction = prompt_template.format(original_text=user_input)\n",
        "\n",
        "    text = f\"<|START_OF_TURN_TOKEN|><|USER_TOKEN|>{language_token}{instruction}<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>\"\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "vBTPiAb24tQP"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_correction(\n",
        "    model,\n",
        "    input: pd.Series,\n",
        "    tokenizer,\n",
        "    parameters: dict,\n",
        "    seq_lenght: int\n",
        "):\n",
        "    input = formatting_prompts_func(input)\n",
        "    input_ids = tokenizer(\n",
        "        [input],\n",
        "        padding=True,\n",
        "        return_tensors=\"pt\",\n",
        "    ).input_ids\n",
        "    input_ids = input_ids.to(model.device)\n",
        "    prompt_padded_len = len(input_ids[0])\n",
        "\n",
        "    # Generate corrections\n",
        "    gen_tokens = model.generate(\n",
        "        input_ids,\n",
        "        temperature=parameters.baseline.temperature,\n",
        "        top_p=parameters.baseline.top_p,\n",
        "        top_k=parameters.baseline.top_k,\n",
        "        max_new_tokens=seq_lenght,\n",
        "        do_sample=True,\n",
        "    )\n",
        "    gen_tokens = [\n",
        "        gt[prompt_padded_len:] for gt in gen_tokens\n",
        "    ]\n",
        "    outputs: list[str] = tokenizer.batch_decode(\n",
        "        gen_tokens,\n",
        "        skip_special_tokens=True\n",
        "    )\n",
        "    # Join divided texts if any\n",
        "    correction = \"\".join(outputs)\n",
        "\n",
        "    return correction\n",
        "\n",
        "test_df[:5][\"target\"] = test_df[:5].progress_apply(lambda x: make_correction(\n",
        "    model=model,\n",
        "    input=x,\n",
        "    tokenizer=tokenizer,\n",
        "    parameters=parameters,\n",
        "    seq_lenght=1600,\n",
        "), axis=1)\n",
        "test_df"
      ],
      "metadata": {
        "id": "cS0fDa2z4SKw",
        "outputId": "4a349891-b678-4026-98f7-fd31ad11007a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        }
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [07:38<00:00, 91.65s/it]\n",
            "<ipython-input-102-0620bec5f089>:38: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_df[:5][\"target\"] = test_df[:5].progress_apply(lambda x: make_correction(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        language                           essay_id split  \\\n",
              "2          czech  tei-skript2012_10-cb1ajanjak_01_1  test   \n",
              "8          czech  tei-skript2012_10-cb1akuband_02_1  test   \n",
              "10         czech  tei-skript2012_10-cb1apexpet_01_1  test   \n",
              "14         czech  tei-skript2012_10-cb1ckaijan_02_1  test   \n",
              "17         czech  tei-skript2012_10-cb1cpolrob_02_1  test   \n",
              "...          ...                                ...   ...   \n",
              "23984  ukrainian                               1364  test   \n",
              "24219  ukrainian                               1600  test   \n",
              "24266  ukrainian                               1647  test   \n",
              "24332  ukrainian                               1713  test   \n",
              "24417  ukrainian                               1799  test   \n",
              "\n",
              "                                                 feature  \\\n",
              "2      Osnova: I. ÚVOD – Co chci\\nII. STAŤ: a) černé ...   \n",
              "8      Tak tady žiji ࿄ Z komínů stoupají dýmy spálené...   \n",
              "10     : − pohled do zrcadla ࿄ −\\n1) shrnutí obou obr...   \n",
              "14     Slohová práce školní\\nJana Kaiserová\\n17. květ...   \n",
              "17     Slohová práce školní\\n17. května 2005\\nTémata:...   \n",
              "...                                                  ...   \n",
              "23984  Будь-яка активність, яку можна об'ярликувати ц...   \n",
              "24219  \"Як, - запитав я, - завадив вам?\"\\n\\n- Своїм н...   \n",
              "24266  Якби не ревіння води, якби не розкати грому, я...   \n",
              "24332  Побачивши, як поводиться з вельми сумнівними в...   \n",
              "24417  Мені як людині дуже складно видавати бажане за...   \n",
              "\n",
              "                                                  target  \n",
              "2      ebezpečí\\nVyhrát!\\nPrávě hraji nejdůležitější ...  \n",
              "8                                                    NaN  \n",
              "10                                                   NaN  \n",
              "14                                                   NaN  \n",
              "17                                                   NaN  \n",
              "...                                                  ...  \n",
              "23984                                                NaN  \n",
              "24219                                                NaN  \n",
              "24266                                                NaN  \n",
              "24332                                                NaN  \n",
              "24417                                                NaN  \n",
              "\n",
              "[2804 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b6985fac-bb05-4ecd-b52e-98213de4d9aa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>language</th>\n",
              "      <th>essay_id</th>\n",
              "      <th>split</th>\n",
              "      <th>feature</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>czech</td>\n",
              "      <td>tei-skript2012_10-cb1ajanjak_01_1</td>\n",
              "      <td>test</td>\n",
              "      <td>Osnova: I. ÚVOD – Co chci\\nII. STAŤ: a) černé ...</td>\n",
              "      <td>ebezpečí\\nVyhrát!\\nPrávě hraji nejdůležitější ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>czech</td>\n",
              "      <td>tei-skript2012_10-cb1akuband_02_1</td>\n",
              "      <td>test</td>\n",
              "      <td>Tak tady žiji ࿄ Z komínů stoupají dýmy spálené...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>czech</td>\n",
              "      <td>tei-skript2012_10-cb1apexpet_01_1</td>\n",
              "      <td>test</td>\n",
              "      <td>: − pohled do zrcadla ࿄ −\\n1) shrnutí obou obr...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>czech</td>\n",
              "      <td>tei-skript2012_10-cb1ckaijan_02_1</td>\n",
              "      <td>test</td>\n",
              "      <td>Slohová práce školní\\nJana Kaiserová\\n17. květ...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>czech</td>\n",
              "      <td>tei-skript2012_10-cb1cpolrob_02_1</td>\n",
              "      <td>test</td>\n",
              "      <td>Slohová práce školní\\n17. května 2005\\nTémata:...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23984</th>\n",
              "      <td>ukrainian</td>\n",
              "      <td>1364</td>\n",
              "      <td>test</td>\n",
              "      <td>Будь-яка активність, яку можна об'ярликувати ц...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24219</th>\n",
              "      <td>ukrainian</td>\n",
              "      <td>1600</td>\n",
              "      <td>test</td>\n",
              "      <td>\"Як, - запитав я, - завадив вам?\"\\n\\n- Своїм н...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24266</th>\n",
              "      <td>ukrainian</td>\n",
              "      <td>1647</td>\n",
              "      <td>test</td>\n",
              "      <td>Якби не ревіння води, якби не розкати грому, я...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24332</th>\n",
              "      <td>ukrainian</td>\n",
              "      <td>1713</td>\n",
              "      <td>test</td>\n",
              "      <td>Побачивши, як поводиться з вельми сумнівними в...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24417</th>\n",
              "      <td>ukrainian</td>\n",
              "      <td>1799</td>\n",
              "      <td>test</td>\n",
              "      <td>Мені як людині дуже складно видавати бажане за...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2804 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b6985fac-bb05-4ecd-b52e-98213de4d9aa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b6985fac-bb05-4ecd-b52e-98213de4d9aa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b6985fac-bb05-4ecd-b52e-98213de4d9aa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bc5b6047-d985-4e05-9a5b-94a6a691a033\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bc5b6047-d985-4e05-9a5b-94a6a691a033')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bc5b6047-d985-4e05-9a5b-94a6a691a033 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_df",
              "summary": "{\n  \"name\": \"test_df\",\n  \"rows\": 2804,\n  \"fields\": [\n    {\n      \"column\": \"language\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"swedish\",\n          \"english\",\n          \"italian\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"essay_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2801,\n        \"samples\": [\n          \"novinky-test-71630\",\n          \"novinky-train-24007\",\n          \"fb-slevomat-5406\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"split\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"test\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"feature\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2803,\n        \"samples\": [\n          \"P\\u0159ipad\\u00e1 m\\u00ed to jako tank\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"ebezpe\\u010d\\u00ed\\nVyhr\\u00e1t!\\nPr\\u00e1v\\u011b hraji nejd\\u016fle\\u017eit\\u011bj\\u0161\\u00ed z\\u00e1pas m\\u00e9 dosavadn\\u00ed baseballov\\u00e9 kari\\u00e9ry. Mus\\u00edme vyhr\\u00e1t. Ud\\u011bl\\u00e1m pro to v\\u0161e a m\\u00ed spoluhr\\u00e1\\u010di tak\\u00e9. Jsme siln\\u00ed.\\nStav 20:16 pro na\\u0161e soupe\\u0159e. Podle v\\u00fdvoje hry se zd\\u00e1, \\u017ee jsme prohr\\u00e1li. Hr\\u016fzn\\u00fd pocit. M\\u00e1m slzy v o\\u010d\\u00edch, ale nechci, aby to n\\u011bkdo vid\\u011bl. Cel\\u00e1 sezona pry\\u010d. V\\u0161e je pry\\u010d. Takov\\u00e1 \\u0161koda. My to snad nikdy nedok\\u00e1\\u017eeme. Nikdy. Skoro bre\\u010d\\u00edm. V hlav\\u011b temno, chmurn\\u00e9 my\\u0161lenky. Nic nevid\\u00edm pozitivn\\u011b jako v\\u017edy. Vid\\u00edm p\\u0159ed sebou jen celou tu d\\u0159inu. Na\\u0161e snaha je zbyte\\u010dn\\u00e1. Nem\\u00e1 to cenu. Tren\\u00e9\\u0159i jsou tak\\u00e9 \\u201enam\\u011bkko\\u201c. Top\\u00edme se ve vlastn\\u00ed beznad\\u011bji. Te\\u010f u\\u017e chci jenom usnout a na v\\u0161echno zapomenout. Nechci zase za\\u017e\\u00edt tu ostudu, \\u017ee jsme n\\u011bco nedok\\u00e1zali.\\nNajednou vid\\u00edm v\\u0161echno jakoby jin\\u00fdma o\\u010dima. Dostal jsem asi n\\u011bjak\\u00fd impulz. Je to posledn\\u00ed z\\u00e1chv\\u011bv nebo nov\\u00e1 s\\u00edla? Je to zvl\\u00e1\\u0161tn\\u00ed. Nec\\u00edt\\u00edm \\u00fanavu. Ta s\\u00edla mne tla\\u010d\\u00ed d\\u00e1l. A nejsem s\\u00e1m! Najednou v\\u0161ichni jakoby o\\u017e\\u00edvaj\\u00ed. T\\u00fdmu se zmoc\\u0148uje tzv. Nagansk\\u00fd duch. Nevym\\u00fd\\u0161l\\u00edm si. Nefantaz\\u00edruji. Je to tak. Je to realita. Vid\\u00edm to sv\\u00fdma o\\u010dima. Sed\\u00edme u sebe, dr\\u017e\\u00edme se kolem ramen a ml\\u010d\\u00edme. Ka\\u017ed\\u00fd v\\u0161ak uvnit\\u0159 sv\\u00e1d\\u00ed krut\\u00fd boj s \\u00fanavou, s odhodl\\u00e1n\\u00edm. Dvan\\u00e1ct mlad\\u00fdch kluk\\u016f. Ticho. N\\u00e1dhern\\u00fd pocit soudr\\u017enosti, pocit, \\u017ee n\\u011bkam pat\\u0159\\u00edm, \\u017ee n\\u011bco um\\u00edm. A op\\u011bt c\\u00edt\\u00edm tu vnit\\u0159n\\u00ed s\\u00edlu.\\nU\\u017e je to tady. Jdu na p\\u00e1lku, v\\u0161echno je te\\u010f na mn\\u011b. Moment roku. Mo\\u017en\\u00e1 zklamu, my prohrajeme. Ale d\\u00e1m do toho v\\u0161echno, co v sob\\u011b m\\u00e1m, v\\u0161echno, co jsem se kdy nau\\u010dil. Sto procent. \\u017daludek mi d\\u011bl\\u00e1 kotrmelce. Nebo to nen\\u00ed \\u017ealudek? U\\u017e ani nesly\\u0161\\u00edm fanou\\u0161ky. Je jich tu moc. Nesly\\u0161\\u00edm, nevn\\u00edm\\u00e1m. M\\u016fj otec mne ur\\u010dit\\u011b sleduje. Mus\\u00edm mu dok\\u00e1zat, \\u017ee um\\u00edm to, co on. Mus\\u00edm rozhodnout. Na sv\\u00fdch bedrech c\\u00edt\\u00edm obrovskou odpov\\u011bdnost. MUS\\u00cdM! A op\\u011bt ticho. Nic. Vid\\u00edm jen m\\u00ed\\u010d, kter\\u00fd mi nadhod\\u00ed. Ud\\u011bl\\u00e1m to. Zvl\\u00e1dnu to. Kolikr\\u00e1t se mi to ji\\u017e povedlo, tak pro\\u010d ne te\\u010f?? Nesm\\u00edm myslet negativn\\u011b! Absolutn\\u00ed soust\\u0159ed\\u011bn\\u00ed. \\u201eStav z\\u00f3ny\\u201c, tak to naz\\u00fdvaj\\u00ed psychologov\\u00e9. Takhle jsem se je\\u0161t\\u011b nikdy nec\\u00edtil. Ticho, nyn\\u00ed opravdov\\u00e9. Div\\u00e1ci stoj\\u00ed, v\\u0161ichni jsou zticha. C\\u00edt\\u00edm to jako \\u017eivotn\\u00ed zkou\\u0161ku. Nep\\u0159eh\\u00e1n\\u00edm. Je to jako prodlou\\u017een\\u00ed v hokeji, penalty ve fotbale. Bu\\u010f my, nebo oni. J\\u00e1 nebo m\\u00ed\\u010d. Pot\\u00ed se mi prsty. NE! Mus\\u00edm to vydr\\u017eet. U\\u017e to p\\u0159ich\\u00e1z\\u00ed. Protihr\\u00e1\\u010di schv\\u00e1ln\\u011b zdr\\u017euj\\u00ed, cht\\u011bj\\u00ed m\\u011b rozhodit. Je to psychick\\u00e1 hra. Nenech\\u00e1m se. NE.\\nM\\u00ed\\u010d let\\u00ed proti mn\\u011b. M\\u00e1 rychlost kolem 120 kmh-1, mohl by m\\u011b i zab\\u00edt. Nemysl\\u00edm na to. Te\\u010f ne. Fast do insidu. Jako v\\u017edycky. V hlav\\u011b pr\\u00e1zdno. T\\u011blo pracuje samo. Srdce bije. N\\u00e1p\\u0159ah, p\\u00e1lka nahoru, st\\u0159et s m\\u00ed\\u010dem. To je ten pocit, jak\\u00fd jsem cht\\u011bl c\\u00edtit. To je ono. V hlav\\u011b po\\u0159\\u00e1d ticho. To se nic ned\\u011bje?! To se mi to jenom zd\\u00e1lo? Ne, m\\u00fdl\\u00edm se. V\\u0161ichni zadr\\u017euj\\u00ed dech, sleduj\\u00ed m\\u00ed\\u010d. Ano, v\\u016fbec jsem si nev\\u0161iml, \\u017ee m\\u00e1m zav\\u0159en\\u00e9 o\\u010di. Ticho. Tentokr\\u00e1t hrobov\\u00e9. Velk\\u00fd t\\u0159esk, kdy\\u017e hlin\\u00edkov\\u00e1 p\\u00e1lka o rychlosti okolo 100 km/h ude\\u0159\\u00ed do m\\u00ed\\u010de. Jako kdy\\u017e do sebe k\\u0159\\u00edsnou dva paprsky. M\\u00ed\\u010d let\\u00ed, je nesen vzduchem. P\\u0159el\\u00e9t\\u00e1v\\u00e1 \\u010d\\u00e1ru 100 m, tedy homerunu. ANO! To je pocit v\\u00edt\\u011bzstv\\u00ed. To je s\\u00edla!\\nNedok\\u00e1\\u017ei popsat, co to je, takhle zv\\u00edt\\u011bzit. Vyhr\\u00e1l jsem s\\u00e1m nad sebou. Nemohu popsat, jak\\u00e9 to bylo, nejsem novin\\u00e1\\u0159. Siln\\u011bj\\u0161\\u00ed z\\u00e1\\u017eitek jsem v\\u0161ak je\\u0161t\\u011b neza\\u017eil. Tento homerun a toto v\\u00edt\\u011bzstv\\u00ed mne posunuly d\\u00e1l. Takov\\u00e1to v\\u00edt\\u011bzstv\\u00ed mi d\\u00e1vaj\\u00ed s\\u00edlu a motivaci, kdy\\u017e v t\\u011b\\u017ek\\u00fdch zimn\\u00edch m\\u011bs\\u00edc\\u00edch d\\u0159u v posilovn\\u011b \\u010di b\\u011bh\\u00e1m kilometry ve sn\\u011bhu. Tento p\\u0159\\u00edb\\u011bh se odehr\\u00e1l na podzim 2004, dnes se p\\u0159ipravuji na Mistrovstv\\u00ed sv\\u011bta 2008 v Edmontonu a CHCI VYHR\\u00c1VAT.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df[:1].feature.item()"
      ],
      "metadata": {
        "id": "OhQuOl-HR2A4",
        "outputId": "a673c5e9-128a-4d99-d58c-9414402f2735",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Osnova: I. ÚVOD – Co chci\n",
            "II. STAŤ: a) černé myšlenky\n",
            "b) [1]„stav zóny“\n",
            "c) rozhodující okamžik\n",
            "III. ZÁVĚR – Co mi to dalo\n",
            "ROZHODUJÍCÍ OKAMŽIK\n",
            "Vyhrát!\n",
            "Právě hraji nejdůležitější zápas mé dosavadní baseballové kariéry. Musíme vyhrát. Udělám pro to vše a mí spoluhráči také. Jsme silní.\n",
            "Stav 20:16 pro naše soupeře. Podle vývoje hry se zdá, že jsme prohráli. Hrůzný pocit. Mám slzy v očích, ale nechci, aby to někdo viděl. Celá sezona pryč. Vše je pryč. Taková škoda. My to snad nikdy nedokážeme. Nikdy. Skoro brečím. V hlavě temno, chmurné myšlenky. Nic nevidím pozitivně jako vždy. Vidím před sebou jen celou tu dřinu. Naše snaha je zbytečná. Nemá to cenu. Trenéři jsou také „naměkko“. Topíme se ve vlastní beznaději. Teď už chci jenom usnout a na všechno zapomenout. Nechci zase zažít tu ostudu, že jsme něco nedokázali.\n",
            "Najednou vidím všechno jakoby jinýma očima. Dostal jsem asi nějaký impulz. Je to poslední záchvěv nebo nová síla? Je to zvláštní. Necítím únavu. Ta síla mne tlačí dál. A nejsem sám! Najednou všichni jakoby ožívají. Týmu se zmocňuje tzv. Naganský duch. Nevymýšlím si. Nefantazíruji. Je to tak. Je to realita. Vidím to svýma očima. Sedíme u sebe, držíme se kolem ramen a mlčíme. Každý však uvnitř svádí krutý boj s únavou, s odhodláním. Dvanáct mladých kluků. Ticho. Nádherný pocit soudržnosti, pocit, že někam patřím, že něco umím. A opět cítím tu vnitřní sílu.\n",
            "Už je to tady. Jdu na pálku, všechno je teď na mně. Moment roku. Možná zklamu, my prohrajeme. Ale dám do toho všechno, co v sobě mám, všechno, co jsem se kdy naučil. Sto procent. Žaludek mi dělá kotrmelce. Nebo to není žaludek? Už ani neslyším fanoušky. Je jich tu moc. Neslyším, nevnímám. Můj otec mne určitě sleduje. Musím mu dokázat, že umím to, co on. Musím rozhodnout. Na svých bedrech cítím obrovskou odpovědnost. MUSÍM! A opět ticho. Nic. Vidím jen míč, který mi nadhodí. Udělám to. Zvládnu to. Kolikrát se mi to již povedlo, tak proč ne teď?? Nesmím myslet negativně! Absolutní soustředění. „Stav zóny“, tak to nazývají psychologové. Takhle jsem se ještě nikdy necítil. Ticho, nyní opravdové. Diváci stojí, všichni jsou zticha. Cítím to jako životní zkoušku. Nepřeháním. Je to jako prodloužení v hokeji, penalty ve fotbale. Buď my, nebo oni. Já nebo míč. Potí se mi prsty. NE! Musím to vydržet. Už to přichází. Protihráči schválně zdržují, chtějí mě rozhodit. Je to psychická hra. Nenechám se. NE.\n",
            "Míč letí proti mně. Má rychlost kolem 120 kmh-1, mohl by mě i zabít. Nemyslím na to. Teď ne. Fast do insidu. Jako vždycky. V hlavě prázdno. Tělo pracuje samo. Srdce bije. Nápřah, pálka nahoru, střet s míčem. To je ten pocit, jaký jsem chtěl cítit. To je ono. V hlavě pořád ticho. To se nic neděje?! To se mi to jenom zdálo? Ne, mýlím se. Všichni zadržují dech, sledují míč. Ano, vůbec jsem si nevšiml, že mám zavřené oči. Ticho. Tentokrát hrobové. Velký třesk, když hliníková pálka o rychlosti okolo 100 km/h udeří do míče. Jako když do sebe křísnou dva paprsky. Míč letí, je nesen vzduchem. Přelétává čáru 100 m, tedy homerunu. ANO! To je pocit vítězství. To je síla!\n",
            "Nedokáži popsat, co to je, takhle zvítězit. Vyhrál jsem sám nad sebou. Nemohu popsat, jaké to bylo, nejsem novinář. Silnější zážitek jsem však ještě nezažil. Tento homerun a toto vítězství mne posunuly dál. Takováto vítězství mi dávají sílu a motivaci, když v těžkých zimních měsících dřu v posilovně či běhám kilometry ve sněhu. Tento příběh se odehrál na podzim 2004, dnes se připravuji na Mistrovství světa 2008 v Edmontonu a CHCI VYHRÁVAT.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_df[:1].target.item())"
      ],
      "metadata": {
        "id": "mi7NTUWpPPqx",
        "outputId": "761d4ab4-75ce-4b3f-9982-4fa246cdda56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ebezpečí\n",
            "Vyhrát!\n",
            "Právě hraji nejdůležitější zápas mé dosavadní baseballové kariéry. Musíme vyhrát. Udělám pro to vše a mí spoluhráči také. Jsme silní.\n",
            "Stav 20:16 pro naše soupeře. Podle vývoje hry se zdá, že jsme prohráli. Hrůzný pocit. Mám slzy v očích, ale nechci, aby to někdo viděl. Celá sezona pryč. Vše je pryč. Taková škoda. My to snad nikdy nedokážeme. Nikdy. Skoro brečím. V hlavě temno, chmurné myšlenky. Nic nevidím pozitivně jako vždy. Vidím před sebou jen celou tu dřinu. Naše snaha je zbytečná. Nemá to cenu. Trenéři jsou také „naměkko“. Topíme se ve vlastní beznaději. Teď už chci jenom usnout a na všechno zapomenout. Nechci zase zažít tu ostudu, že jsme něco nedokázali.\n",
            "Najednou vidím všechno jakoby jinýma očima. Dostal jsem asi nějaký impulz. Je to poslední záchvěv nebo nová síla? Je to zvláštní. Necítím únavu. Ta síla mne tlačí dál. A nejsem sám! Najednou všichni jakoby ožívají. Týmu se zmocňuje tzv. Naganský duch. Nevymýšlím si. Nefantazíruji. Je to tak. Je to realita. Vidím to svýma očima. Sedíme u sebe, držíme se kolem ramen a mlčíme. Každý však uvnitř svádí krutý boj s únavou, s odhodláním. Dvanáct mladých kluků. Ticho. Nádherný pocit soudržnosti, pocit, že někam patřím, že něco umím. A opět cítím tu vnitřní sílu.\n",
            "Už je to tady. Jdu na pálku, všechno je teď na mně. Moment roku. Možná zklamu, my prohrajeme. Ale dám do toho všechno, co v sobě mám, všechno, co jsem se kdy naučil. Sto procent. Žaludek mi dělá kotrmelce. Nebo to není žaludek? Už ani neslyším fanoušky. Je jich tu moc. Neslyším, nevnímám. Můj otec mne určitě sleduje. Musím mu dokázat, že umím to, co on. Musím rozhodnout. Na svých bedrech cítím obrovskou odpovědnost. MUSÍM! A opět ticho. Nic. Vidím jen míč, který mi nadhodí. Udělám to. Zvládnu to. Kolikrát se mi to již povedlo, tak proč ne teď?? Nesmím myslet negativně! Absolutní soustředění. „Stav zóny“, tak to nazývají psychologové. Takhle jsem se ještě nikdy necítil. Ticho, nyní opravdové. Diváci stojí, všichni jsou zticha. Cítím to jako životní zkoušku. Nepřeháním. Je to jako prodloužení v hokeji, penalty ve fotbale. Buď my, nebo oni. Já nebo míč. Potí se mi prsty. NE! Musím to vydržet. Už to přichází. Protihráči schválně zdržují, chtějí mě rozhodit. Je to psychická hra. Nenechám se. NE.\n",
            "Míč letí proti mně. Má rychlost kolem 120 kmh-1, mohl by mě i zabít. Nemyslím na to. Teď ne. Fast do insidu. Jako vždycky. V hlavě prázdno. Tělo pracuje samo. Srdce bije. Nápřah, pálka nahoru, střet s míčem. To je ten pocit, jaký jsem chtěl cítit. To je ono. V hlavě pořád ticho. To se nic neděje?! To se mi to jenom zdálo? Ne, mýlím se. Všichni zadržují dech, sledují míč. Ano, vůbec jsem si nevšiml, že mám zavřené oči. Ticho. Tentokrát hrobové. Velký třesk, když hliníková pálka o rychlosti okolo 100 km/h udeří do míče. Jako když do sebe křísnou dva paprsky. Míč letí, je nesen vzduchem. Přelétává čáru 100 m, tedy homerunu. ANO! To je pocit vítězství. To je síla!\n",
            "Nedokáži popsat, co to je, takhle zvítězit. Vyhrál jsem sám nad sebou. Nemohu popsat, jaké to bylo, nejsem novinář. Silnější zážitek jsem však ještě nezažil. Tento homerun a toto vítězství mne posunuly dál. Takováto vítězství mi dávají sílu a motivaci, když v těžkých zimních měsících dřu v posilovně či běhám kilometry ve sněhu. Tento příběh se odehrál na podzim 2004, dnes se připravuji na Mistrovství světa 2008 v Edmontonu a CHCI VYHRÁVAT.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xkAHbeH9Rv5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tEyaQxDURdMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yW1PkvfKPOjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z6Jin-73PN4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o3B5W0zQPLJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raise Exception(e)"
      ],
      "metadata": {
        "id": "3_Lz76039Yzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def formatting_prompts_func(example):\n",
        "    language_code = LANG_TO_CODE[example[\"language\"]]\n",
        "    language_token = LANG_CODE_TO_TOKEN[language_code]\n",
        "\n",
        "    user_input = example['feature']\n",
        "    prompt_template = multigec_prompts[example[\"language\"]].prompt_template\n",
        "    instruction = prompt_template.format(original_text=user_input)\n",
        "    target = example['target']\n",
        "\n",
        "    text = f\"<|START_OF_TURN_TOKEN|><|USER_TOKEN|>{language_token}{instruction}<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>{target}\"\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "fyrJgA5cOqIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_added_toks = tokenizer.add_tokens(\n",
        "    [v for v in LANG_CODE_TO_TOKEN.values()],\n",
        "    special_tokens=True\n",
        ")\n",
        "model.resize_token_embeddings(len(tokenizer))"
      ],
      "metadata": {
        "id": "vCZ22H5qWpOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQjCg7j6G3SL"
      },
      "outputs": [],
      "source": [
        "training_dataset = Dataset.from_pandas(train_df)\n",
        "val_dataset = Dataset.from_pandas(val_df)\n",
        "\n",
        "seq_length = 1300\n",
        "\n",
        "cld_train_dataset = ConstantLengthDataset(\n",
        "    tokenizer=tokenizer,\n",
        "    dataset=training_dataset,\n",
        "    #dataset_text_field='feature',\n",
        "    seq_length=seq_length,\n",
        "    eos_token_id=tokenizer.eos_token_id,\n",
        "    shuffle=True,\n",
        "    append_concat_token=True,\n",
        "    add_special_tokens=True,\n",
        "    formatting_func=formatting_prompts_func,\n",
        ")\n",
        "cld_val_dataset = ConstantLengthDataset(\n",
        "    tokenizer=tokenizer,\n",
        "    dataset=val_dataset,\n",
        "    #dataset_text_field='feature',\n",
        "    seq_length=int(seq_length/2),\n",
        "    eos_token_id=tokenizer.eos_token_id,\n",
        "    shuffle=True,\n",
        "    append_concat_token=True,\n",
        "    add_special_tokens=True,\n",
        "    formatting_func=formatting_prompts_func,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMLq8PqqwozH"
      },
      "outputs": [],
      "source": [
        "# parameters.training[\"gradient_accumulation_steps\"] = 8\n",
        "# parameters.training[\"per_device_train_batch_size\"] = 5\n",
        "# parameters.training[\"per_device_eval_batch_size\"] = 2\n",
        "# # Try these\n",
        "# parameters.training[\"lr_scheduler_type\"] = \"cosine\"\n",
        "# parameters.training[\"max_grad_norm\"] = 1.0\n",
        "# parameters.training[\"output_dir\"] = \"results\"\n",
        "# parameters.training[\"num_train_epochs\"] = 12\n",
        "# parameters.training[\"eval_strategy\"] = \"steps\"\n",
        "# parameters.training[\"save_strategy\"] = \"steps\"        # Save model after every step\n",
        "# parameters.training[\"metric_for_best_model\"] = \"eval_loss\"\n",
        "# parameters.training[\"greater_is_better\"] = False\n",
        "# parameters.training[\"group_by_length\"] = False # we already use CLD\n",
        "# parameters.training[\"save_total_limit\"] = 3           # Keep only the 3 most recent checkpoints\n",
        "# parameters.training[\"load_best_model_at_end\"] = True # EarlyStoppingCallback requires load_best_model_at_end = True\n",
        "# parameters.training[\"warmup_steps\"] = 50\n",
        "# parameters.training[\"learning_rate\"] = 3e-5\n",
        "# parameters.training[\"save_steps\"] = 25\n",
        "# parameters.training[\"weight_decay\"] = 0.0\n",
        "# early_stopping_patience = 75"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cld_train_dataset"
      ],
      "metadata": {
        "id": "3v8tP2pMK4PO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fsUN8A2hPc02"
      },
      "outputs": [],
      "source": [
        "dict(parameters.training)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def formatting_prompts_func_old(example):\n",
        "#     output_texts = []\n",
        "#     for i in range(len(example['inputs'])):\n",
        "#         language_code = LANG_TO_CODE[example[\"language\"]]\n",
        "#         language_token = LANG_CODE_TO_TOKEN[language_code]\n",
        "\n",
        "#         user_input = example['inputs'][i]\n",
        "#         prompt_template = multigec_prompts[example[\"language\"]]\n",
        "#         instruction = prompt_template.format(original_text=user_input)\n",
        "#         target = example['targets'][i]\n",
        "\n",
        "\n",
        "#         text = f\"<|START_OF_TURN_TOKEN|><|USER_TOKEN|>{language_token}{instruction}<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>{target}\"\n",
        "#         output_texts.append(text)\n",
        "#     return output_texts\n",
        "\n",
        "# def formatting_prompts_func(example):\n",
        "#     language_code = LANG_TO_CODE[example[\"language\"]]\n",
        "#     language_token = LANG_CODE_TO_TOKEN[language_code]\n",
        "\n",
        "#     user_input = example['feature']\n",
        "#     prompt_template = multigec_prompts[example[\"language\"]]\n",
        "#     instruction = prompt_template.format(original_text=user_input)\n",
        "#     target = example['target']\n",
        "\n",
        "#     text = f\"<|START_OF_TURN_TOKEN|><|USER_TOKEN|>{language_token}{instruction}<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>{target}\"\n",
        "\n",
        "#     return text"
      ],
      "metadata": {
        "id": "vEwN6naIKID6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fXDzcmVNJ7D"
      },
      "outputs": [],
      "source": [
        "run = wandb.init(\n",
        "    project=wandb_project_name,\n",
        "    job_type=\"training\",\n",
        "    anonymous=\"allow\"\n",
        ")\n",
        "\n",
        "wandb.config.update(dict(parameters.training))\n",
        "\n",
        "peft_config = LoraConfig(\n",
        "    r=parameters.lora.r,\n",
        "    lora_alpha=parameters.lora.lora_alpha,\n",
        "    target_modules=list(parameters.lora.target_modules),\n",
        "    bias=parameters.lora.bias,\n",
        "    task_type=parameters.lora.task_type\n",
        ")\n",
        "training_arguments = SFTConfig(\n",
        "    **parameters.training,\n",
        "    packing=True,\n",
        "    max_seq_length=seq_length,\n",
        "    output_dir=out_model_dir,\n",
        ")\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=cld_train_dataset,\n",
        "    eval_dataset=cld_val_dataset,\n",
        "    peft_config=peft_config,\n",
        "    args=training_arguments,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=parameters.early_stopping.early_stopping_patience)],\n",
        "    #formatting_func=formatting_prompts_func,\n",
        ")\n",
        "\n",
        "with torch.backends.cuda.sdp_kernel(\n",
        "    enable_flash=True,\n",
        "    enable_math=False,\n",
        "    enable_mem_efficient=False\n",
        "):\n",
        "    trainer.unload() # Should remove peft warnings\n",
        "    trainer.train(resume_from_checkpoint=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HnKaZ7pbCxG_"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "run_name = wandb.run.name\n",
        "model_out_path = f\"/gdrive/MyDrive/models/multigec/{run_name}\"\n",
        "os.makedirs(model_out_path, exist_ok=True)\n",
        "trainer.model.save_pretrained(model_out_path)\n",
        "wandb.save(model_out_path + \"/*\")\n",
        "model.config.use_cache = True\n",
        "model.eval()\n",
        "time.sleep(30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "test_df = multigec_df.loc[multigec_df.loc[:, \"split\"] == \"test\"]\n",
        "\n",
        "def make_correction(\n",
        "    model,\n",
        "    input: pd.Series,\n",
        "    tokenizer,\n",
        "    parameters: dict,\n",
        "    seq_lenght: int\n",
        "):\n",
        "    language: str = input[\"language\"]\n",
        "    language_code: str = LANG_TO_CODE[language]\n",
        "    language_token: str = LANG_CODE_TO_TOKEN[language_code]\n",
        "    prompt_template: PromptTemplate = multigec_prompts[language]\n",
        "\n",
        "    # Prepare inputs\n",
        "    inputs: list[str] = sentences(input)\n",
        "    inputs = [language_token + prompt_template.format(original_text=input) for input in inputs]\n",
        "    inputs: list[dict[str, str]] = get_message_format(inputs)\n",
        "    input_ids = tokenizer.apply_chat_template(\n",
        "        inputs,\n",
        "        tokenize=True,\n",
        "        add_generation_prompt=True,\n",
        "        padding=True,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "    input_ids = input_ids.to(model.device)\n",
        "    prompt_padded_len = len(input_ids[0])\n",
        "\n",
        "    # Generate corrections\n",
        "    gen_tokens = model.generate(\n",
        "        input_ids,\n",
        "        temperature=parameters.baseline.temperature,\n",
        "        top_p=parameters.baseline.top_p,\n",
        "        top_k=parameters.baseline.top_k,\n",
        "        max_new_tokens=seq_lenght,\n",
        "        do_sample=True,\n",
        "    )\n",
        "    gen_tokens = [\n",
        "        gt[prompt_padded_len:] for gt in gen_tokens\n",
        "    ]\n",
        "    outputs: list[str] = tokenizer.batch_decode(\n",
        "        gen_tokens,\n",
        "        skip_special_tokens=True\n",
        "    )\n",
        "    # Join divided texts if any\n",
        "    correction = \"\".join(outputs)\n",
        "\n",
        "    return correction\n",
        "\n",
        "test_df.progress_apply(lambda x: make_correction(\n",
        "    model=model,\n",
        "    input=x,\n",
        "    tokenizer=tokenizer,\n",
        "    parameters=parameters,\n",
        "    seq_lenght=seq_length,\n",
        "))\n",
        "test_df"
      ],
      "metadata": {
        "id": "H_H5HvEYUK_F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "test_df.to_csv(out_path)"
      ],
      "metadata": {
        "id": "477hrCXNUK_F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9CUMSMx6vyM"
      },
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SoTVI79YGic_"
      },
      "outputs": [],
      "source": [
        "raise Exception e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NER-tGaxxE_e"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "SJnYGEZIUK_F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "!pip install pynvml -q"
      ],
      "metadata": {
        "id": "33M51z4NUK_F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "shMkTieDUK_F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "id": "cl0vFnbdUK_F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "import time\n",
        "from pynvml import nvmlInit, nvmlDeviceGetHandleByIndex, nvmlDeviceGetMemoryInfo\n",
        "\n",
        "def wait_until_enough_gpu_memory(min_memory_available, max_retries=10, sleep_time=5):\n",
        "    nvmlInit()\n",
        "    handle = nvmlDeviceGetHandleByIndex(torch.cuda.current_device())\n",
        "\n",
        "    for _ in range(max_retries):\n",
        "        clear_gpu_memory()\n",
        "        info = nvmlDeviceGetMemoryInfo(handle)\n",
        "        if info.free >= min_memory_available:\n",
        "            break\n",
        "        print(f\"Waiting for {min_memory_available} bytes of free GPU memory. Retrying in {sleep_time} seconds...\")\n",
        "        time.sleep(sleep_time)\n",
        "    else:\n",
        "        raise RuntimeError(f\"Failed to acquire {min_memory_available} bytes of free GPU memory after {max_retries} retries.\")\n",
        "\n",
        "# Usage example\n",
        "min_memory_available = 38 * 1024 * 1024 * 1024  # 30GB\n",
        "clear_gpu_memory()\n",
        "wait_until_enough_gpu_memory(min_memory_available)"
      ],
      "metadata": {
        "id": "x-twetpFUK_F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "del model"
      ],
      "metadata": {
        "id": "4nyUXVAPUK_F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "del trainer"
      ],
      "metadata": {
        "id": "xi5q_6xLUK_G"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2eee8ca85121462082e88ce307aee5ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9c999855ca7d4fd98b6f16128cf10df4",
              "IPY_MODEL_f931f4e24a4b48ef9f7e1d9606518331",
              "IPY_MODEL_c203414ceaf842ebbb46a9764d11c78c"
            ],
            "layout": "IPY_MODEL_67c6b481780d4561b924d43d9be0e85a"
          }
        },
        "9c999855ca7d4fd98b6f16128cf10df4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c5d9bc68b2b4ee0992f60e66e4c777a",
            "placeholder": "​",
            "style": "IPY_MODEL_f2abe29a43934883ba27e1f2a3db3b87",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "f931f4e24a4b48ef9f7e1d9606518331": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_375fec489ffa442098cc2c851e9d8d36",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c8956e6046a64df6ac3024b659883aef",
            "value": 4
          }
        },
        "c203414ceaf842ebbb46a9764d11c78c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84c06e67211e4ecbb2628e19500524ab",
            "placeholder": "​",
            "style": "IPY_MODEL_063563ce187b4d92b16e5d614e5ffd72",
            "value": " 4/4 [00:12&lt;00:00,  2.63s/it]"
          }
        },
        "67c6b481780d4561b924d43d9be0e85a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c5d9bc68b2b4ee0992f60e66e4c777a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2abe29a43934883ba27e1f2a3db3b87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "375fec489ffa442098cc2c851e9d8d36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8956e6046a64df6ac3024b659883aef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "84c06e67211e4ecbb2628e19500524ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "063563ce187b4d92b16e5d614e5ffd72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}