{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Reennon/multigec-models/blob/main/notebooks/gemma_3_12b/multigec/multigec_prediction_minimal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UsXRO225aQG5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"GIT_TOKEN\"] = userdata.get('git_token')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "metadata": {
        "id": "aduMiBeD946F",
        "outputId": "55b8fe7f-38ee-432d-87b5-e2e6f637e91a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "J_IRXNxZaF4Y",
        "outputId": "e75a7824-f5c0-4eb6-a4cb-bacbde1c92d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'multigec-models' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://$GIT_TOKEN@github.com/Reennon/multigec-models.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "u7b_-L4YdQdS",
        "outputId": "2e82670e-4115-4250-9917-a99f39dc39e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/multigec-models\n"
          ]
        }
      ],
      "source": [
        "%cd multigec-models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ak_WBUcgdWYE",
        "outputId": "6341da6a-5679-4132-f320-bb67f7c56f84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ],
      "source": [
        "!git pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "M0zzclvTdlkE",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3dbf33e-4852-4949-d8a3-cdd9a508a794"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "adapters 1.1.0 requires transformers~=4.47.1, but you have transformers 4.52.0.dev0 which is incompatible.\n",
            "wtpsplit 2.1.1 requires huggingface-hub==0.25.2, but you have huggingface-hub 0.30.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -U bitsandbytes peft accelerate datasets sentencepiece wandb python-dotenv wtpsplit -q\n",
        "!pip install flash-attn --no-build-isolation -q\n",
        "!pip install wtpsplit==2.1.1 -q\n",
        "!pip install syntok==1.4.4 -q\n",
        "!pip install omegaconf -q\n",
        "!pip install wandb -q\n",
        "!pip install --upgrade git+https://github.com/huggingface/transformers.git -q\n",
        "!pip install --upgrade trl -q\n",
        "!pip install pandas numpy -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xLa_z_uleW1O"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from omegaconf import OmegaConf\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoConfig\n",
        "from huggingface_hub import login\n",
        "from src.utils.multigec import sentences, LANG_TO_CODE, LANG_CODE_TO_TOKEN\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "from src.instruction_templates import multigec_prompts\n",
        "\n",
        "import torch\n",
        "import wandb\n",
        "\n",
        "from transformers import BitsAndBytesConfig\n",
        "from tqdm import tqdm\n",
        "from trl.trainer import ConstantLengthDataset\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from transformers.trainer_callback import EarlyStoppingCallback\n",
        "\n",
        "from transformers import TrainingArguments\n",
        "from trl import SFTConfig, SFTTrainer\n",
        "from peft import LoraConfig, PeftModelForCausalLM\n",
        "\n",
        "tqdm.pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ZrXeF2PMTA9C"
      },
      "outputs": [],
      "source": [
        "parameters = OmegaConf.load(\"./params/gemma_3_12b.yaml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2orS0nY-j3QY"
      },
      "outputs": [],
      "source": [
        "track     = \"minimal\"\n",
        "model_name = \"gemma-3-12b-it\"\n",
        "fine_tuned_model_name = f\"gemma-3-12b-it-multigec\"\n",
        "experiment_name = f\"multigec-{track}-{model_name}\"\n",
        "\n",
        "hf_key   = userdata.get(\"hf_key\")\n",
        "secret_wandb = userdata.get(\"wandb_key\")\n",
        "in_path  = f\"/gdrive/MyDrive/multigec/datasets/multigec_{track}.csv\"\n",
        "\n",
        "# Path where the output will be saved to\n",
        "out_path = f\"/gdrive/MyDrive/multigec/preds/{model_name}/multigec_test_{track}.csv\"\n",
        "out_model_dir = f\"/gdrive/MyDrive/multigec/models/multigec/{fine_tuned_model_name}\"\n",
        "QUANTIZE_4BIT = True\n",
        "device   = \"cuda:0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5ATeEv_etKR1"
      },
      "outputs": [],
      "source": [
        "login(hf_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "oB4Vv3zFyHLd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52db4952-33bb-493b-d0c5-cd729d1b3a8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: ‘-q’: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!env TORCH_USE_CUDA_DSA=1 -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = \"google/gemma-3-12b-it\"\n",
        "saved_checkpoint = out_model_dir + \"/checkpoint-500-minimal-best\"\n",
        "\n",
        "quantization_config = None\n",
        "if QUANTIZE_4BIT:\n",
        "  quantization_config = BitsAndBytesConfig(\n",
        "      load_in_4bit=True,\n",
        "      bnb_4bit_quant_type=\"nf4\",\n",
        "      bnb_4bit_use_double_quant=True,\n",
        "      bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "      bnb_4bit_quant_storage=torch.bfloat16,\n",
        "  )\n",
        "tokenizer = AutoTokenizer.from_pretrained(saved_checkpoint)\n",
        "config = AutoConfig.from_pretrained(base_model)\n",
        "config.text_config.use_cache = False\n",
        "base_model_instance = AutoModelForCausalLM.from_pretrained(\n",
        "    base_model,\n",
        "    config=config,\n",
        "    quantization_config=quantization_config,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=device,\n",
        "    attn_implementation=\"eager\",\n",
        ")\n",
        "base_model_instance.resize_token_embeddings(len(tokenizer))\n",
        "model = PeftModelForCausalLM.from_pretrained(\n",
        "    base_model_instance,\n",
        "    saved_checkpoint,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=device,\n",
        "    ignore_mismatched_sizes=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "rsH6g6IGgmy1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190,
          "referenced_widgets": [
            "0bded2f4fdc14fe0a967b2414c7b963a",
            "74e4d3a3cf36469eacc56d91bc8539be",
            "a2d925368f6a4b2fa208cd6ee406962e",
            "ffbdbf62b5ad4e268c49538d789980e5",
            "58d27e1e65844cfab305fd8f6eb7fffb",
            "0e5f6ccffff34a0e801ff6bee0c0e1c0",
            "59c7b2c552794d1ba5f388c2ac0b930d",
            "7542a0fa34d5451abe28984a747553d3",
            "009bea269a0240e7bbf33ce871b56147",
            "7bdd8c71d8404de795fa89f05233d2f5",
            "be986227be70460693f8975ca193fb8c"
          ]
        },
        "outputId": "85c0a029-a635-4645-c54e-69ad3b52b472"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "You have set `use_cache` to `False`, but cache_implementation is set to hybrid. cache_implementation will have no effect.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0bded2f4fdc14fe0a967b2414c7b963a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "tc_-2FtptNPf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e00b7807-dd07-4b9c-838e-28bb6197176e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-a28f7b9e78be>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_df.target = None\n"
          ]
        }
      ],
      "source": [
        "multigec_df = pd.read_csv(in_path)\n",
        "train_df = multigec_df.loc[multigec_df.loc[:, \"split\"] == \"train\"]\n",
        "val_df = multigec_df.loc[multigec_df.loc[:, \"split\"] == \"val\"]\n",
        "test_df = multigec_df.loc[multigec_df.loc[:, \"split\"] == \"test\"]\n",
        "test_df.target = None"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def formatting_prompts_func(example):\n",
        "    language_code = LANG_TO_CODE[example[\"language\"]]\n",
        "    # Since special tokens for Gemma models does not have |, we remove them\n",
        "    language_token = LANG_CODE_TO_TOKEN[language_code].replace(\"|\", \"\")\n",
        "\n",
        "    user_input = example['feature']\n",
        "    prompt_template = multigec_prompts[example[\"language\"]].prompt_template\n",
        "    instruction = prompt_template.format(original_text=user_input)\n",
        "\n",
        "    text = f\"<start_of_turn>user\\n{language_token}{instruction}<end_of_turn>\\n<start_of_turn>model\\n\"\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "d8xqBfvlPGnc"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "max_new_tokens = 1600\n",
        "batch_size = 15\n",
        "save_each = 15\n",
        "\n",
        "# Assume test_df already exists and out_path is defined.\n",
        "# Filter rows that need processing (target is empty/NaN).\n",
        "to_process_df = test_df[test_df[\"target\"].isna()].reset_index()  # preserve original index in \"index\" column\n",
        "\n",
        "def collate_fn(examples):\n",
        "    indices = [ex[\"index\"] for ex in examples]\n",
        "    texts = [formatting_prompts_func(example) for example in examples]\n",
        "    tokenized = tokenizer(\n",
        "        texts,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    tokenized[\"indices\"] = indices\n",
        "    return tokenized\n",
        "\n",
        "\n",
        "# Create DataLoader using only the rows that need processing.\n",
        "dataloader = DataLoader(\n",
        "    to_process_df.to_dict(orient=\"records\"),\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "processed_rows = 0\n",
        "for batch in tqdm(dataloader):\n",
        "    input_ids = batch[\"input_ids\"].to(model.device)\n",
        "    attention_mask = batch.get(\"attention_mask\", None)\n",
        "    if attention_mask is not None:\n",
        "        attention_mask = attention_mask.to(model.device)\n",
        "    prompt_padded_len = len(input_ids[0])\n",
        "\n",
        "    gen_tokens = model.generate(\n",
        "        input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        temperature=parameters.baseline.temperature,\n",
        "        top_p=parameters.baseline.top_p,\n",
        "        top_k=parameters.baseline.top_k,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        do_sample=True,\n",
        "    )\n",
        "\n",
        "    # Remove the prompt tokens from the generated tokens\n",
        "    gen_tokens = [gt[prompt_padded_len:] for gt in gen_tokens]\n",
        "\n",
        "    # Decode generated tokens to text corrections\n",
        "    corrections = tokenizer.batch_decode(gen_tokens, skip_special_tokens=True)\n",
        "    corrections = [\"\".join(c) for c in corrections]\n",
        "\n",
        "    # Update the original DataFrame using the indices provided in the batch.\n",
        "    for idx, corr in zip(batch[\"indices\"], corrections):\n",
        "        test_df.loc[idx, \"target\"] = corr\n",
        "        processed_rows += 1\n",
        "\n",
        "        if processed_rows % save_each == 0:\n",
        "            test_df.to_csv(out_path, index=False)\n",
        "            print(f\"Saved progress after processing {processed_rows} rows.\")\n",
        "\n",
        "# Final save after processing all batches.\n",
        "test_df.to_csv(out_path, index=False)\n",
        "print(\"Final save complete!\")\n"
      ],
      "metadata": {
        "id": "TJN5Jz1b-w6m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1219978f-171d-4d58-91ed-42285adcfbda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/141 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "  1%|          | 1/141 [06:09<14:23:19, 370.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved progress after processing 20 rows.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|▏         | 2/141 [07:53<8:14:06, 213.28s/it] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved progress after processing 40 rows.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "\n",
        "gc.collect(generation=2)"
      ],
      "metadata": {
        "id": "PUuxRxC1LM9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "iFxNoz-5LTO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "shMkTieDUK_F"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0bded2f4fdc14fe0a967b2414c7b963a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_74e4d3a3cf36469eacc56d91bc8539be",
              "IPY_MODEL_a2d925368f6a4b2fa208cd6ee406962e",
              "IPY_MODEL_ffbdbf62b5ad4e268c49538d789980e5"
            ],
            "layout": "IPY_MODEL_58d27e1e65844cfab305fd8f6eb7fffb"
          }
        },
        "74e4d3a3cf36469eacc56d91bc8539be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e5f6ccffff34a0e801ff6bee0c0e1c0",
            "placeholder": "​",
            "style": "IPY_MODEL_59c7b2c552794d1ba5f388c2ac0b930d",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "a2d925368f6a4b2fa208cd6ee406962e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7542a0fa34d5451abe28984a747553d3",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_009bea269a0240e7bbf33ce871b56147",
            "value": 5
          }
        },
        "ffbdbf62b5ad4e268c49538d789980e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bdd8c71d8404de795fa89f05233d2f5",
            "placeholder": "​",
            "style": "IPY_MODEL_be986227be70460693f8975ca193fb8c",
            "value": " 5/5 [00:28&lt;00:00,  5.86s/it]"
          }
        },
        "58d27e1e65844cfab305fd8f6eb7fffb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e5f6ccffff34a0e801ff6bee0c0e1c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59c7b2c552794d1ba5f388c2ac0b930d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7542a0fa34d5451abe28984a747553d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "009bea269a0240e7bbf33ce871b56147": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7bdd8c71d8404de795fa89f05233d2f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be986227be70460693f8975ca193fb8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}