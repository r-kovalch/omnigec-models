{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Reennon/multigec-models/blob/main/notebooks/aya_expanse_8b/multigec/multigec_plus_wikiedits_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsXRO225aQG5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"GIT_TOKEN\"] = userdata.get('git_token')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "aduMiBeD946F",
        "outputId": "d8da099e-9df0-46c3-e12b-aacb44e0f300",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_IRXNxZaF4Y",
        "outputId": "48f790ea-b348-4196-9125-b56c33df598d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'multigec-models' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://$GIT_TOKEN@github.com/Reennon/multigec-models.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7b_-L4YdQdS",
        "outputId": "ed4b7813-8175-4a3e-edae-d875a1e47196"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/multigec-models\n"
          ]
        }
      ],
      "source": [
        "%cd multigec-models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ak_WBUcgdWYE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3525450c-39f8-4e16-b2d6-ac93104c7806"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ],
      "source": [
        "!git pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0zzclvTdlkE",
        "outputId": "50bbe0c2-7c87-415c-e399-ddfb61567235",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "wtpsplit 2.1.1 requires huggingface-hub==0.25.2, but you have huggingface-hub 0.30.1 which is incompatible.\n",
            "adapters 1.1.0 requires transformers~=4.47.1, but you have transformers 4.50.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -U bitsandbytes peft accelerate datasets sentencepiece wandb python-dotenv wtpsplit -q\n",
        "!pip install flash-attn --no-build-isolation -q\n",
        "!pip install wtpsplit==2.1.1 -q\n",
        "!pip install syntok==1.4.4 -q\n",
        "!pip install omegaconf -q\n",
        "!pip install wandb -q\n",
        "!pip install --upgrade transformers trl -q\n",
        "!pip install pandas numpy -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLa_z_uleW1O"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from omegaconf import OmegaConf\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoConfig\n",
        "from huggingface_hub import login\n",
        "from src.utils.multigec import sentences, LANG_TO_CODE, LANG_CODE_TO_TOKEN\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "from src.instruction_templates import multigec_prompts\n",
        "\n",
        "import torch\n",
        "import wandb\n",
        "\n",
        "from transformers import BitsAndBytesConfig\n",
        "from tqdm import tqdm\n",
        "from trl.trainer import ConstantLengthDataset\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from transformers.trainer_callback import EarlyStoppingCallback\n",
        "\n",
        "from transformers import TrainingArguments\n",
        "from trl import SFTConfig, SFTTrainer\n",
        "from peft import LoraConfig\n",
        "\n",
        "from peft import PeftModel, PeftModelForCausalLM\n",
        "\n",
        "tqdm.pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrXeF2PMTA9C"
      },
      "outputs": [],
      "source": [
        "parameters = OmegaConf.load(\"./params/aya_expanse_8b.yaml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2orS0nY-j3QY"
      },
      "outputs": [],
      "source": [
        "track     = \"minimal\"\n",
        "fine_tuned_model_name = f\"aya-expanse-8b-omnigec-minimal\"\n",
        "\n",
        "hf_key   = userdata.get(\"hf_key\")\n",
        "secret_wandb = userdata.get(\"wandb_key\")\n",
        "\n",
        "in_path  = f\"/content/drive/MyDrive/multigec/preds/multigec_test_{track}.csv\"\n",
        "out_path = f\"/content/drive/MyDrive/multigec/preds/omnigec_test_{track}.csv\"\n",
        "\n",
        "out_model_dir = f\"/content/drive/MyDrive/multigec/multigec/models/{fine_tuned_model_name}\"\n",
        "QUANTIZE_4BIT = True\n",
        "device   = \"cuda:0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ATeEv_etKR1"
      },
      "outputs": [],
      "source": [
        "login(hf_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oB4Vv3zFyHLd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be9cddf6-6025-4b7c-ddb0-fe4eac12e3fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: ‘-q’: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!env TORCH_USE_CUDA_DSA=1 -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225,
          "referenced_widgets": [
            "6ba9c138c98642339ed79010c9ff1543",
            "82106d818b834dd5bb2d152462455f5d",
            "8d9fa4fbe2ca43819907402eaf15d4e3",
            "202aac30ac9e410cae94ccefa3c8b660",
            "9fa40477b64a401c958795f7dfd9c575",
            "7b90ae45b82a43bd9b880506a95165f9",
            "191186ed007642f083baef8f378e938c",
            "7a219c29154644f28965f222f8875ec5",
            "96edca37c90e412cabeef0daa58d1ada",
            "a315a49e4df14a0e85e62784e6d3bb30",
            "f66476741a4540d9a160770b973cc62c"
          ]
        },
        "id": "npCYpk8StL1L",
        "outputId": "3fed99d8-f66b-48be-b928-3a698f7d7dcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6ba9c138c98642339ed79010c9ff1543"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:470: UserWarning: Some weights of PeftModelForCausalLM were not initialized from the model checkpoint and are being ignored because you passed `ignore_mismatched_sizes=True`: - base_model.model.lm_head.weight: found shape torch.Size([255040, 4096]) in the checkpoint and torch.Size([255029, 4096]) in the model instantiated\n",
            "- base_model.model.model.embed_tokens.weight: found shape torch.Size([255040, 4096]) in the checkpoint and torch.Size([255029, 4096]) in the model instantiated.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "base_model = \"CohereForAI/aya-expanse-8b\"\n",
        "saved_checkpoint = out_model_dir + \"/checkpoint-4300\"\n",
        "\n",
        "quantization_config = None\n",
        "if QUANTIZE_4BIT:\n",
        "  quantization_config = BitsAndBytesConfig(\n",
        "      load_in_4bit=True,\n",
        "      bnb_4bit_quant_type=\"nf4\",\n",
        "      bnb_4bit_use_double_quant=True,\n",
        "      bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "  )\n",
        "tokenizer = AutoTokenizer.from_pretrained(saved_checkpoint)\n",
        "config = AutoConfig.from_pretrained(base_model)\n",
        "base_model_instance = AutoModelForCausalLM.from_pretrained(\n",
        "    base_model,\n",
        "    config=config,\n",
        "    quantization_config=quantization_config,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=device,\n",
        "    attn_implementation=\"flash_attention_2\",\n",
        ")\n",
        "base_model_instance.resize_token_embeddings(len(tokenizer))\n",
        "model = PeftModelForCausalLM.from_pretrained(\n",
        "    base_model_instance,\n",
        "    saved_checkpoint,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=device,\n",
        "    ignore_mismatched_sizes=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tc_-2FtptNPf"
      },
      "outputs": [],
      "source": [
        "test_df = pd.read_csv(in_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def formatting_prompts_func(example):\n",
        "    language_code = LANG_TO_CODE[example[\"language\"]]\n",
        "    language_token = LANG_CODE_TO_TOKEN[language_code]\n",
        "\n",
        "    user_input = example['feature']\n",
        "    prompt_template = multigec_prompts[example[\"language\"]].prompt_template\n",
        "    instruction = prompt_template.format(original_text=user_input)\n",
        "\n",
        "    text = f\"<|START_OF_TURN_TOKEN|><|USER_TOKEN|>{language_token}{instruction}<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>\"\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "vBTPiAb24tQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "max_new_tokens = 1600\n",
        "batch_size = 100\n",
        "save_each = 100\n",
        "\n",
        "# Assume test_df already exists and out_path is defined.\n",
        "# Filter rows that need processing (target is empty/NaN).\n",
        "to_process_df = test_df[test_df[\"target\"].isna()].reset_index()  # preserve original index in \"index\" column\n",
        "\n",
        "def collate_fn(examples):\n",
        "    indices = [ex[\"index\"] for ex in examples]\n",
        "    texts = [formatting_prompts_func(example) for example in examples]\n",
        "    tokenized = tokenizer(\n",
        "        texts,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    tokenized[\"indices\"] = indices\n",
        "    return tokenized\n",
        "\n",
        "\n",
        "# Create DataLoader using only the rows that need processing.\n",
        "dataloader = DataLoader(\n",
        "    to_process_df.to_dict(orient=\"records\"),\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "processed_rows = 0\n",
        "for batch in tqdm(dataloader):\n",
        "    input_ids = batch[\"input_ids\"].to(model.device)\n",
        "    attention_mask = batch.get(\"attention_mask\", None)\n",
        "    if attention_mask is not None:\n",
        "        attention_mask = attention_mask.to(model.device)\n",
        "    prompt_padded_len = len(input_ids[0])\n",
        "\n",
        "    gen_tokens = model.generate(\n",
        "        input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        temperature=parameters.baseline.temperature,\n",
        "        top_p=parameters.baseline.top_p,\n",
        "        top_k=parameters.baseline.top_k,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        do_sample=True,\n",
        "    )\n",
        "\n",
        "    # Remove the prompt tokens from the generated tokens\n",
        "    gen_tokens = [gt[prompt_padded_len:] for gt in gen_tokens]\n",
        "\n",
        "    # Decode generated tokens to text corrections\n",
        "    corrections = tokenizer.batch_decode(gen_tokens, skip_special_tokens=True)\n",
        "    corrections = [\"\".join(c) for c in corrections]\n",
        "\n",
        "    # Update the original DataFrame using the indices provided in the batch.\n",
        "    for idx, corr in zip(batch[\"indices\"], corrections):\n",
        "        test_df.loc[idx, \"target\"] = corr\n",
        "        processed_rows += 1\n",
        "\n",
        "        if processed_rows % save_each == 0:\n",
        "            test_df.to_csv(out_path, index=False)\n",
        "            print(f\"Saved рprogress after processing {processed_rows} rows.\")\n",
        "\n",
        "# Final save after processing all batches.\n",
        "test_df.to_csv(out_path, index=False)\n",
        "print(\"Final save complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJN5Jz1b-w6m",
        "outputId": "4233b5f2-09fb-4314-b6fa-6c554cebea5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/16 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            " 31%|███▏      | 5/16 [16:07<32:42, 178.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved progress after processing 50 rows.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 62%|██████▎   | 10/16 [31:03<19:23, 194.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved progress after processing 100 rows.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 94%|█████████▍| 15/16 [45:42<03:04, 184.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved progress after processing 150 rows.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [47:30<00:00, 178.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final save complete!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "-kuc_5OVv5O_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6ba9c138c98642339ed79010c9ff1543": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_82106d818b834dd5bb2d152462455f5d",
              "IPY_MODEL_8d9fa4fbe2ca43819907402eaf15d4e3",
              "IPY_MODEL_202aac30ac9e410cae94ccefa3c8b660"
            ],
            "layout": "IPY_MODEL_9fa40477b64a401c958795f7dfd9c575"
          }
        },
        "82106d818b834dd5bb2d152462455f5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b90ae45b82a43bd9b880506a95165f9",
            "placeholder": "​",
            "style": "IPY_MODEL_191186ed007642f083baef8f378e938c",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "8d9fa4fbe2ca43819907402eaf15d4e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a219c29154644f28965f222f8875ec5",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_96edca37c90e412cabeef0daa58d1ada",
            "value": 4
          }
        },
        "202aac30ac9e410cae94ccefa3c8b660": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a315a49e4df14a0e85e62784e6d3bb30",
            "placeholder": "​",
            "style": "IPY_MODEL_f66476741a4540d9a160770b973cc62c",
            "value": " 4/4 [00:13&lt;00:00,  2.76s/it]"
          }
        },
        "9fa40477b64a401c958795f7dfd9c575": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b90ae45b82a43bd9b880506a95165f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "191186ed007642f083baef8f378e938c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a219c29154644f28965f222f8875ec5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96edca37c90e412cabeef0daa58d1ada": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a315a49e4df14a0e85e62784e6d3bb30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f66476741a4540d9a160770b973cc62c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}